{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/badoil/ML/blob/master/bert_finetuned.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "TuXvD6IPzvlF"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "RbGIu_eZ0JUR"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tE5tT2P20fWV",
        "outputId": "679fa719-6cc9-46e3-cd67-517fb68f29a8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "device"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "M2R7Z_GR02fm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a289c14-86ca-4553-f5ad-685c4b851c9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully installed datasets-2.14.4 dill-0.3.7 huggingface-hub-0.16.4 multiprocess-0.70.15 safetensors-0.3.3 tokenizers-0.13.3 transformers-4.32.0 xxhash-3.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iL2v5Mp1rYhH"
      },
      "outputs": [],
      "source": [
        "from transformers import BertTokenizer, BertForSequenceClassification\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim     # Adam Optimizer\n",
        "from datasets import load_dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "sAehKOo6rtW9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35,
          "referenced_widgets": [
            "1d6e9722555640fab42cbb14c5cb47d5"
          ]
        },
        "outputId": "70302f13-256e-4064-b7db-3a2a55ec7afe"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1d6e9722555640fab42cbb14c5cb47d5"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "dataset = load_dataset(\"nsmc\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGIs9FUDszCH",
        "outputId": "3025686b-95af-45cc-d783-52dff4a8b94a"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['id', 'document', 'label'],\n",
              "        num_rows: 150000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['id', 'document', 'label'],\n",
              "        num_rows: 50000\n",
              "    })\n",
              "})"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zM7RsRgBtn3l",
        "outputId": "2e0e4275-aab5-490d-e1f3-ab4cb3e61b6f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0, 1, 0, 0, 1, 0, 0, 0, 1, 1]"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "dataset['train']['label'][:10]  # 0부정리뷰 1긍정리뷰"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2DUsqc9GttDM"
      },
      "outputs": [],
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-multilingual-cased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "2QzZPnL0ubDx"
      },
      "outputs": [],
      "source": [
        "inputs = tokenizer(dataset['train']['document'], padding=True, truncation=True, max_length=512, return_tensors=\"pt\")    # embedding matrix 만들기 위해서 각 문장 벡터의 차원, 즉 토큰 갯수를 가장 긴 문장의 토큰 갯수에 맞춤"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "WWgWZZ0YyqlI"
      },
      "outputs": [],
      "source": [
        "labels = torch.tensor(dataset['train']['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33gNw32MzBOG",
        "outputId": "90130b32-e72b-4777-e853-eae3da1c054e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "inputs.keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JF7RoUAozMVE"
      },
      "outputs": [],
      "source": [
        "inputs['input_ids'].shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "609siTl10MxT",
        "outputId": "0c283908-13f4-49d1-93c7-8016b0a4f5b6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs['attention_mask']    # padding 으로 들어간 토큰들은 0으로 표현해서 없애줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "v5Y6tl970Ydn"
      },
      "outputs": [],
      "source": [
        "inputs_test = tokenizer(dataset['test']['document'], padding=True, truncation=True, max_length=512, return_tensors=\"pt\")    # embedding matrix 만들기 위해서 각 문장 벡터의 차원, 즉 토큰 갯수를 가장 긴 문장의 토큰 갯수에 맞춤\n",
        "labels_test = torch.tensor(dataset['test']['label'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "G8beyIdz01-l"
      },
      "outputs": [],
      "source": [
        "train_dataset = TensorDataset(inputs.input_ids, inputs.attention_mask, labels)  # pytorch dataset인 TensorDataset 으로 만들어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "G8JRLK7r18-z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7ff248c-1003-47f9-a098-d640242de386"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "#train_dataset[0]    # (input_ids, attention_mask, labels) 이런식으로 한 문장의 정보를 표현\n",
        "#inputs['input_ids'][0]\n",
        "inputs['attention_mask'][0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9s7AZTa_23o7"
      },
      "outputs": [],
      "source": [
        "test_dataset = TensorDataset(inputs_test.input_ids, inputs_test.attention_mask, labels_test)  # pytorch dataset인 TensorDataset 으로 만들어줌"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "FcrDAOJp3Fr0"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)    # batch_size 학습효율에 영향 미침"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hcwsiYk-3nlJ",
        "outputId": "064cd3e5-8b3a-4e9e-a872-05ba171d70f3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4688"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(train_loader)   # 150000 = 32 * 4688    # 한 batch 마다 업뎃되므로 이 모델은 총 4688번 업뎃됨"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "7JZZbdsF3qx-"
      },
      "outputs": [],
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5XRnN4PP4Bzo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45388a5d-cb29-4f0a-af3b-422f8a2c638e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)     # BertForSequenceClassification 이것은 feedforward fully connected layer + softmax 해서 classification 하는 클래스"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kXsfBnci5XLp"
      },
      "outputs": [],
      "source": [
        "model.to(device)    # 모델의 파라미터들을 지금 이 colab의 메모리 gpu에 올린다"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "ikeCaOk9524y"
      },
      "outputs": [],
      "source": [
        "optimizer = optim.AdamW(model.parameters(), lr=1e-5)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()     # multi-class classification\n",
        "EPOCH = 1\n",
        "PRINT_EVERY_N = 400"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fMpv-PjO9pMi"
      },
      "outputs": [],
      "source": [
        "model.train()   # train 모드로 바꿈"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd_i2psb9vHO",
        "outputId": "3cb3b358-8436-45a3-8962-966325919f77"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epoch: 1, batch: 400, avg_loss:0.5361\n",
            "epoch: 1, batch: 800, avg_loss:0.4481\n",
            "epoch: 1, batch: 1200, avg_loss:0.4112\n",
            "epoch: 1, batch: 1600, avg_loss:0.3840\n",
            "epoch: 1, batch: 2000, avg_loss:0.3731\n",
            "epoch: 1, batch: 2400, avg_loss:0.3693\n",
            "epoch: 1, batch: 2800, avg_loss:0.3584\n",
            "epoch: 1, batch: 3200, avg_loss:0.3496\n",
            "epoch: 1, batch: 3600, avg_loss:0.3528\n",
            "epoch: 1, batch: 4000, avg_loss:0.3479\n",
            "epoch: 1, batch: 4400, avg_loss:0.3445\n"
          ]
        }
      ],
      "source": [
        "for epoch in range(EPOCH):\n",
        "  running_loss = 0.0\n",
        "  for i, batch in enumerate(train_loader):\n",
        "    optimizer.zero_grad()   # batch 마다 미분값 초기화\n",
        "    input_ids, attention_mask, labels = [b.to(device) for b in batch]   # gpu에 보낸후 리스트에 담기\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)   # BERT에 따라서 attention 계산됨, 여기서 logit 값이 output\n",
        "    loss = loss_fn(outputs.logits, labels)    # 확률값, 32개 배치사이즈의 평균 확률값이 나옴\n",
        "    loss.backward()   # 역전파\n",
        "    optimizer.step()  # 역전파 미분값으로 파라미터 업데이트\n",
        "\n",
        "    running_loss += loss.item()\n",
        "    if ((i % PRINT_EVERY_N == 0) and (i > 0)):\n",
        "      avg_loss = running_loss / PRINT_EVERY_N\n",
        "      print(f\"epoch: {epoch+1}, batch: {i}, avg_loss:{avg_loss:.4f}\")\n",
        "      running_loss = 0.0\n",
        "    print(\"finished\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r8ASLkzgC45t"
      },
      "outputs": [],
      "source": [
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "total_correct = 0\n",
        "total_count = 0\n",
        "with torch.no_grad():\n",
        "  for batch in test_loader:\n",
        "    input_ids, attention_mask, labels = [b.to(device) for b in batch]\n",
        "    outputs = model(input_ids, attention_mask=attention_mask)\n",
        "    logits = outputs.logits\n",
        "    predictions = torch.argmax(logits, dim=1)\n",
        "    correct = (predictions == labels).sum().item()    # boolean 값을 integer로 바꿈\n",
        "    total_correct += correct\n",
        "    total_count += labels.size(0)"
      ],
      "metadata": {
        "id": "4QZtC1bRLTQt"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# accuracy = total_correct / total_count * 100\n",
        "# print(f\"accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eqzkge4MQC5W",
        "outputId": "7f814cd0-3b7e-46f9-8b0a-2377e0648100"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accuracy: 3.13\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(sentence: str):\n",
        "  #tokenizing\n",
        "  inputs = tokenizer(dataset['train']['document'], padding=True, truncation=True, max_length=512, return_tensors=\"pt\")\n",
        "  input_ids = inputs['input_ids'].to(device)\n",
        "  attention_mask = inputs['attention_mask'].to(device)\n",
        "\n",
        "  # forward\n",
        "  outputs = model(input_ids, attention_mask=attention_mask)\n",
        "  logits = outputs.logits\n",
        "  prediction = torch.argmax(logits, dim=1).item()\n",
        "\n",
        "  return prediction"
      ],
      "metadata": {
        "id": "-j5U0MhyQmFe"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMAqCtjUlvnP++sjXQz0Cbm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {}
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}